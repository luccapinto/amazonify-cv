import boto3
from botocore.exceptions import ClientError
import json

def analisar_cv_com_bedrock(texto_cv, texto_vaga):
    """
    Analyzes a resume against a job description using Amazon Bedrock.

    :param texto_cv: The text of the resume.
    :param texto_vaga: The text of the job description.
    :return: The analysis generated by the AI, or an error message.
    """
    try:
        # Create a Bedrock client
        # Substitua 'us-east-1' pela região da AWS que você configurou
        bedrock_client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')
        
        # Model ID
        # O model ID foi atualizado para o que você está usando agora.
        model_id = "amazon.nova-micro-v1:0"

        # Prompt engineering
        prompt = f"""
        Você é um recrutador "Bar Raiser" da Amazon. Sua tarefa é analisar o seguinte currículo em relação à vaga de emprego fornecida,
        com foco especial nos Princípios de Liderança da Amazon.

        Currículo:
        {texto_cv}

        Vaga de Emprego:
        {texto_vaga}

        Sua análise deve:
        1.  Avaliar a aderência do currículo à vaga, destacando pontos fortes e fracos.
        2.  Analisar o currículo sob a ótica dos Princípios de Liderança da Amazon, como "Customer Obsession", "Ownership", e "Invent and Simplify". Forneça exemplos do currículo que demonstrem (ou não) esses princípios.
        3.  Sugerir melhorias concretas no currículo. Para cada sugestão, mostre como reescrever trechos usando o método STAR (Situação, Tarefa, Ação, Resultado) para evidenciar o impacto das realizações do candidato.
        4.  Formate sua resposta final usando Markdown para garantir a legibilidade.
        """

        # Monta a mensagem para a API converse
        conversation = [
            {
                "role": "user",
                "content": [{"text": prompt}],
            }
        ]

        # Invoca o modelo usando a API converse
        response = bedrock_client.converse(
            modelId=model_id,
            messages=conversation,
            # Configurações de inferência, como no exemplo
            inferenceConfig={"maxTokens": 4096, "temperature": 0.5, "topP": 0.9},
        )

        # Extrai o texto da resposta
        analysis = response["output"]["message"]["content"][0]["text"]

        return analysis

    except (ClientError, Exception) as e:
        print(f"Erro ao analisar com o Bedrock: {e}")
        return f"Ocorreu um erro ao processar a sua solicitação. Verifique as configurações e credenciais da AWS. Erro: {e}"